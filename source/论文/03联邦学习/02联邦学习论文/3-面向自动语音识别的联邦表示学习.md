# 面向自动语音识别的联邦表示学习

英文名：Federated Representation Learning for Automatic Speech Recognition

论文链接：https://arxiv.org/abs/2308.02013

联邦学习（FL）是一种保护隐私的范例，允许边缘设备协作学习而无需共享数据。像Alexa和Siri这样的边缘设备是潜在的未标记音频数据源，可以用来学习强大的音频表征。在这项工作中，我们将自监督学习（SSL）和FL结合起来，以学习符合数据隐私约束的自动语音识别（ASR）表示。我们使用未标记的语音数据集Libri-Light中的说话者和章节信息来模拟非IID（非独立同分布）的说话者分隔数据分布，并使用FedSGD框架对LSTM编码器进行预训练。我们展示了在FL中预训练的ASR编码器表现与中央预训练模型一样好，并与无预训练相比，可以提高12-15%（WER）。我们进一步将联邦预训练模型调整到一种新的语言，法语，并展示相比无预训练的情况，可以提高20%（WER）。

