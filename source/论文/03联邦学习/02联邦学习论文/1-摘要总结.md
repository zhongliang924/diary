# 摘要总结

**2-Federated Learning Meets Natural Language Processing: A Survey**

论文链接：https://arxiv.org/abs/2107.12603v1

联邦学习旨在从多个分散的边缘设备（例如移动设备）或服务器上学习机器学习模型，而无需牺牲本地数据隐私。最近的自然语言处理技术依赖于深度学习和大型预训练语言模型。然而，大型深度神经网络和语言模型通常是通过大量数据在服务器端进行训练的。由于文本数据广泛来自最终用户，因此在这项工作中，我们研究了最近使用联邦学习作为学习框架的自然语言处理模型和技术。我们的调查讨论了联邦自然语言处理中的主要挑战，包括算法挑战、系统挑战以及隐私问题。我们还对现有的联邦自然语言处理评估方法和工具进行了批判性审查。最后，我们突出了当前的研究差距和未来方向。



**3-Federated Representation Learning for Automatic Speech Recognition**

论文链接：https://arxiv.org/abs/2308.02013

联邦学习（FL）是一种保护隐私的范例，允许边缘设备协作学习而无需共享数据。像Alexa和Siri这样的边缘设备是潜在的未标记音频数据源，可以用来学习强大的音频表征。在这项工作中，我们将自监督学习（SSL）和FL结合起来，以学习符合数据隐私约束的自动语音识别（ASR）表示。我们使用未标记的语音数据集Libri-Light中的说话者和章节信息来模拟非IID（非独立同分布）的说话者分隔数据分布，并使用FedSGD框架对LSTM编码器进行预训练。我们展示了在FL中预训练的ASR编码器表现与中央预训练模型一样好，并与无预训练相比，可以提高12-15%（WER）。我们进一步将联邦预训练模型调整到一种新的语言，法语，并展示相比无预训练的情况，可以提高20%（WER）。



**4-Training Speech Recognition Models with Federated Learning: A Quality/Cost Framework**

论文链接：https://arxiv.org/abs/2010.15965

我们提出使用联邦学习，一种分散的设备上学习范例，来训练语音识别模型。通过按用户进行每轮的训练，联邦学习必须承担处理非独立同分布（non-IID）数据分布的成本，这些数据分布预计会对训练模型的质量产生负面影响。我们提出了一个框架，通过这个框架，可以改变非独立同分布程度，从而展示模型质量与联邦训练的计算成本之间的权衡关系，我们通过一种新颖的度量来捕捉这种关系。最后，我们证明，通过超参数优化和适当使用变分噪声，可以弥补非独立同分布对模型质量的影响，同时减少成本。



**5-A federated approach in training acoustic models**

论文链接：http://www.interspeech2020.org/uploadfile/pdf/Mon-2-11-4.pdf

在本论文中，描述了一种基于联邦学习（FL）的声学模型训练新平台。这是首次尝试在语音识别（SR）任务中引入联邦学习技术。除了任务的新颖性之外，本论文还描述了一个易于泛化的FL平台，并提出了用于此任务的设计决策。在引入的新算法中，包括采用成对优化器的分层优化方案和梯度选择算法，从而提高了训练时间和SR性能。梯度选择算法基于在聚合步骤中加权梯度。它实际上充当了梯度传播之前的正则化过程。这个过程可能解决了联邦学习面临的挑战之一，即在非常异构的数据上进行训练。提议的系统的实验验证基于LibriSpeech任务，显示了1.5倍的加速和6%的WERR。提议的联邦学习系统似乎在收敛速度和整体模型性能方面优于分布式训练的黄金标准。在内部任务中还有进一步的改进。



**6-End-to-End Speech Recognition from Federated Acoustic Models**

论文链接：https://ieeexplore.ieee.org/abstract/document/9747161

在联邦学习（FL）设置下训练自动语音识别（ASR）模型近来引起了广泛关注。然而，文献中经常出现的FL场景往往是人为的，未能捕捉到真实FL系统的复杂性。在本论文中，我们构建了一个具有挑战性和现实性的ASR联邦实验设置，其中包括具有异构数据分布的客户端，使用CommonVoice数据集的法语和意大利语数据集部分，这是一个庞大的异构数据集，包含数千名不同的说话者、声学环境和噪音。我们首次进行了关于基于注意力的序列到序列端到端（E2E）ASR模型的实证研究，涵盖了三种聚合加权策略——标准FedAvg、基于损失的聚合和一种新颖的基于字错误率（WER）的聚合，在两个现实的FL场景中进行了比较：跨存储单元（cross-silo）包括10个客户端和跨设备（cross-device）包括2K和4K客户端。我们对来自异构和现实FL声学模型的E2E ASR进行的分析为未来基于现实FL的ASR应用的研究和开发奠定了基础。



**7-Federated self-learning with weak supervision for speech recognition**

论文链接：https://ieeexplore.ieee.org/abstract/document/10096983

