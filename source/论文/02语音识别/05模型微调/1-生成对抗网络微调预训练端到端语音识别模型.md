# 生成对抗网络微调预训练端到端语音识别模型

英文名：FINE-TUNING OF PRE-TRAINED END-TO-END SPEECH RECOGNITION WITH GENERATIVE ADVERSARIAL NETWORKS

论文链接：https://arxiv.org/abs/2103.13329

最近，使用生成对抗网络（GAN）对低资源ASR语料库进行端到端（E2E）ASR系统的对抗训练已经开始探索。GAN有助于通过一个两个玩家的极小极大博弈来学习真实的数据表示。然而，使用GAN框架对大型ASR语料库进行E2E ASR模型的训练从未被探索过，因为由于高方差的梯度更新和收敛问题，这可能需要过长的时间。在本文中，我们引入了一种新的框架，用于使用GAN目标微调预训练的ASR模型，其中ASR模型充当生成器，而鉴别器试图区分ASR输出和真实数据。由于ASR模型是预先训练的，我们假设ASR模型的输出（软分布向量）有助于从鉴别器获得更高的分数，并在我们的GAN框架内使鉴别器的任务更加困难，从而提高了在微调阶段的ASR模型的性能。在这里，预训练的ASR模型通过额外的对抗损失对抗性地针对鉴别器进行微调。对全面的LibriSpeech数据集的实验显示，我们提出的方法优于基线和传统的基于GAN的对抗模型。

## 1、方法

- 生成训练

  ASR模型充当以语音信号为条件的生成器，预测相应的转录文本。鉴别器试图区分真实转录和ASR转录。在训练过程中，对真实转录给予更高的分数，对ASR转录给予更低的分数。本文采用生成训练微调预训练E2E ASR模型，其中使用sequence-to-sequence和CTC loss进行训练。ASR模型微调期间，鉴别器参数是固定的，ASR模型通过额外的对抗性损失进行训练，并生成ASR转录以欺骗鉴别器（即从鉴别器中获得更高的分数）。ASR模型和鉴别器交替训练，并相互学习。算法1描述了用于预训练ASR模型的对抗微调算法，下面将描述鉴别器和ASR网络体系架构。

  ![](../../../figs.assets/image-20230515212903139.png)

- 鉴别网络

  鉴别网络的输入是 ground-truth 和 ASR 输出转录，它返回标量$s$作为质量分数(quality score)，鉴别网络示例如图所示：

  ![](../../../figs.assets/image-20230517131204645.png)

  图1 鉴别器网络

  首先通过线性变换将真实文本或ASR输出映射到较低的维度（128），然后应用128核，核大小为2x1，步长为1的两个CNN1D层提取每个时间索引的特征，在层之间应用batch norm，最后在时间轴上计算平均特征，然后将其映射到具有线性投影的单个标量值。

  为了训练鉴别器，引入Wasserstein GAN方法作为改进版本，还引入梯度惩罚。鉴别器用于估计ground-truth转录

- ASR架构

  提出的方法可以适用于任何ASR网络架构。本文使用基于transformer的网络架构，联合CTC和注意力，模型架构示意如图2所示：

  ![](../../../figs.assets/image-20230529161306101.png)

  图2 ASR模型架构

  鉴别器是将$\hat{Y}$作为输入。

- 使用GAN微调ASR模型

  在图3中，预训练ASR模型采用编码器-解码器架构，充当GAN网络的生成器G，鉴别器D试图将ASR转录与Ground Truth区分开，由于ASR模型是预训练的，鉴别器不能很容易区分这两种转录，这有助于训练更强的鉴别器。鉴别器和生成器是交替训练。
  ![](../../../figs.assets/image-20230529163507160.png)

  图3 使用GAN微调ASR模型

  算法1解释了对抗性训练的微调过程：

  ![](../../../figs.assets/image-20230529164354513.png)

## 2、实验结果

采用 LibriSpeech 数据集进行实验。

  ![](../../../figs.assets/image-20230529165546559.png)

