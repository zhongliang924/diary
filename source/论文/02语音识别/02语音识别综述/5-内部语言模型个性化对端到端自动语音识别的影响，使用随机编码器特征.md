# 内部语言模型个性化对端到端自动语音识别的影响，使用随机编码器特征

论文链接：https://ieeexplore.ieee.org/document/10022938

端到端（E2E）语音转文本模型通常需要转录音频进行训练和个性化。**我们引入了使用随机音频编码器特征而非语音的方法**，以微调最终模型层并从仅文本数据中获取新的词汇。在用户提供任何语音数据之前，这种技术可用于设备上的个性化。我们通过在混合自回归 transducer（HAT）模型上进行模拟用户实验，使用基于conformer的编码器和简单文本嵌入进行标签处理，展示了对新词汇的召回率和离线测试集上的词误率（WER）的改进。我们将这种方法与合成音频的使用进行了比较，发现随机编码器特征在计算成本较低的情况下更有益。实验证明，通过更新构成内部语言模型一部分的特定网络组件，可以获得最大的收益。

## 引言

领先的自动语音识别（ASR）程序采用深度神经网络，以端到端（E2E）的方式使用录制的人类语音和相应的文本进行训练。**相对于先前使用单独训练的组件（如声学、发音和语言模型）的方法，E2E训练通过更紧凑的模型在高资源情境中取得了卓越的性能**[1, 2, 3, 4, 5]。对于在移动设备上运行的ASR系统，模型的紧凑性尤为重要，因为这些设备有更严格的计算限制[6]。即使有大量转录的音频用于训练，仍然存在许多罕见的词汇和名字，基础模型可能难以捕捉，尤其是在轻量级、设备上运行的程序的有限容量下[7, 8]。因此，在**部署这样的ASR系统时，对罕见和用户特定的词汇的准确性仍然是一个突出的挑战，也是个性化的核心用例**。

尽管我们的基准ASR模型是端到端训练的，但它们的架构仍包含具有不同形式的组件。具体而言，**这些组件包括1) 音频编码器网络，2) 文本预测网络，以及3) “联合”网络**，它将（1）和（2）的输出结合起来生成最终的词片概率[9]。理想情况下，用户提供了配对的文本和音频数据以一起训练所有组件。然而，在许多情况下，只有文本数据更容易获得。此外，**在设备上进行个性化期间，通常只对端到端模型的最后几层进行微调**[10]。在这种情况下，我们的指导性见解是，仍然应该能够在新单词上训练内部语言模型，并因此提高整体ASR性能，而无需真实音频数据。为此，我们提出在微调过程中用随机值替换音频编码器输出。在标准的RNN-T损失函数下，**随机编码器特征刺激联合网络，同时学习新单词**。这种方法允许内部语言模型从仅文本数据中获取新的词汇，并且无需引入任何新的模型组件。虽然它的性能不如使用真实音频进行训练，但我们将展示我们的方法至少与使用文本转语音（TTS）输入进行模拟音频的学习一样好，因此避免了运行潜在昂贵的语音合成器的需要。

本文的剩余部分组织如下。在第2节中，我们描述了先前用于设备上ASR模型个性化的方法。在第3节中，我们介绍了随机编码器值的方法，并在回顾RNN-Transducer损失函数的相关细节后进行了说明。第4节详细说明了我们的实验方法和结果，包括与使用真实和合成音频的比较、超参数敏感性以及其他消融实验，最后在第5节进行讨论。

## 相关工作

尽管存在计算、数据保留、调度和功耗方面的限制，但先前的研究表明嵌入式模型可以通过微调[11, 12, 10, 13]、偏置[14, 15, 16]或融合[17, 18, 19, 20]等方法进行用户个性化。我们简要讨论这些技术及其权衡。

### 微调

微调需要训练，考虑到有限的功率、时间和内存，这可能很困难，但其优势在于每个示例只需要恒定的工作量，并且在训练中使用的训练数据不需要在训练后存储。<font color="red"> 微调方法还可以集成到联邦语音系统中，改进未来的基础模型，而无需收集用户数据[21]。</font>为了减少过拟合、处理和存储需求，通常会冻结大部分网络，例如仅保留早期编码器层[13]或晚期解码器层[12]，具体取决于预期的领域。我们的方法依赖于冻结整个编码器，因为在训练期间其输出被替换为随机数。

先前的微调方法通常倾向于使用用户或领域的转录音频，而不仅仅是文本，这在第1节中提到了一些缺点。在使用仅文本数据增强非个性化ASR模型的训练方面已经取得了成功[22, 23, 24, 25, 26]，特别是在资源有限的情况下[27, 28, 29]。然而，我们只了解到在设备上个性化的初步研究取得了部分成功[12]，这可能是因为在用户设备上合成足够的音频可能会面临困难。**我们的贡献是通过使用随机编码器特征而不是文本转语音，绕过这些困难**。





