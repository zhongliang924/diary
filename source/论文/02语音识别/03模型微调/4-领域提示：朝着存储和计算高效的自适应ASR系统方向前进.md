# 领域提示：朝着存储和计算高效的自适应ASR系统方向前进

英文名：DOMAIN PROMPTS: TOWARDS MEMORY AND COMPUTE EFFICIENT DOMAIN ADAPTATION OF ASR SYSTEMS

论文链接：https://arxiv.org/abs/2112.08718v1

自动语音识别（ASR）系统已在各种各样的领域应用中找到了用途。由于领域特定的系统在领域内评估中表现优于其通用对应物，因此显然需要具备存储和计算高效的**领域自适应**。特别是，对于用于重新评分ASR假设的参数大的基于Transformer的语言模型进行适应具有挑战性。在这项工作中，我们介绍了**领域提示**（domain-prompts）方法，该方法训练了少量领域**令牌嵌入参数**，以使基于Transformer的语言模型适应特定领域。仅使用每个领域的少量额外参数，我们在未经调整的语言模型基线上实现了7-14%的词错误率（WER）改善。尽管参数高效，但这些改善效果与拥有数亿参数的完全微调模型相当。通过在提示大小、数据集大小、初始化和领域上进行消融实验，我们提供了使用领域提示在ASR系统中的好处的证据。

## 引言

自动语音识别（ASR）系统构成了各个行业产品的关键组成部分。由于它们在性能方面的最新进展[1, 2, 3]，已经在包括医疗保健、旅行预订和客户服务在内的广泛领域中得到了部署。进一步提高这些系统性能的典型技术是使用外部语言模型（LM）对n个最佳假设进行重新评分，因为与标记的音频数据相比，文本数据更容易获得[3, 4]。最近基于Transformer的语言模型，如GPT-2 [5]和BERT [6]，在各种语言建模任务中都表现出了与传统模型相比的显著增益。然而，这些语言模型包含数百万个参数，将它们调整为资源有限的领域特定ASR系统存在挑战。维护多个领域适应的这些LM的副本是不可扩展的，因为涉及到大量的内存、计算和维护成本。另一方面，适用于所有领域的通用版本的LM在性能上不如领域特定的LM [7, 8]。因此，明显存在在性能和成本之间找到平衡的需求。

最近的语言建模文献[9, 10, 11, 12, 13, 8]包括了解决将大型语言模型高效适应特定任务的新方法。与为每个任务进行微调和存储数百万个参数不同，它们提出了一些关于使用通用的与任务无关的LM副本以及每个任务的有限附加参数的思路。因此，这些方法在成本和每个独立任务的性能之间达到了所需的平衡。例如，AdapterHub [9]引入了与冻结的预训练LM权重一起的新的任务特定层，而Leopard [11]提出了一种基于元学习的方法，可以使用来自未知任务的很少训练示例来快速适应预训练参数。更近期的模型，如GPT-3 [14]，能够借助描述任务的单词（称为提示）来解决新任务。

与为NLP任务调整语言模型不同，本文侧重于ASR系统的领域自适应，扩展了[**15**]的工作。我们的目标是学习一组小型领域特定参数，以比未经调整的基于Transformer的语言模型更好地评分领域特定的ASR假设。我们从任务自适应中借鉴了提示微调（prompt-tuning）[10]的思想，引入了用于实现我们目标的领域提示。我们将领域提示定义为领域特定的嵌入，当添加到任何句子的令牌嵌入前，并通过基本的语言模型，可以得到该领域特定句子的发生概率。在我们的领域自适应方法中，可训练参数的数量（提示令牌的数量乘以嵌入大小）远小于LM的大小，但却实现了与完全微调的领域特定LM相似的性能。我们的主要贡献总结如下：(1) 我们以参数高效的方式引入领域提示，以使基于Transformer的语言模型适应特定领域，(2) 在小内存和计算开销下，我们展示了与使用普通的、开箱即用的LM的ASR系统相比，WER改善了7-14%，(3) 特别是在低数据环境中，我们的方法与完全微调的模型性能相匹配，甚至击败了其他LM自适应方法，尽管它仅使用完整模型参数的<0.3%。

