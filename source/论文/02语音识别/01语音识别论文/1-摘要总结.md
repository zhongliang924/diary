# 摘要总结

## 语音识别综述

**Recent Advance in End-to-End Automatic Speech Recognition**

论文链接：https://arxiv.org/abs/2111.01690

最近，语音领域出现了一个重要趋势，即从基于深度神经网络的混合建模转向端到端（E2E）建模，用于自动语音识别（ASR）。尽管在ASR准确性方面，E2E模型在大多数基准测试中取得了最先进的结果，但混合模型目前仍在许多商业ASR系统中占有很大比例。有许多实际因素影响了生产模型部署决策。传统的混合模型经过几十年的生产优化，通常在这些因素上表现良好。如果E2E模型不能为所有这些因素提供出色的解决方案，那么它们很难在商业上广泛应用。在本文中，我们将概述E2E模型的最新进展，重点关注从工业角度解决这些挑战的技术。



**A Comparative Study On Transformer VS RNN In Speech Applications**

论文链接：https://arxiv.org/abs/1909.06317

序列到序列（sequence-to-sequence）模型已广泛用于端到端语音处理，例如自动语音识别（ASR）、语音翻译（ST）和文本到语音合成（TTS）。本文重点关注一种新兴的序列到序列模型称为Transformer，在神经机器翻译和其他自然语言处理应用中取得了最先进的性能。我们进行了深入的研究，在15个ASR、一个多语言ASR、一个ST和两个TTS基准测试中，对Transformer和传统的循环神经网络（RNN）进行了实验比较和分析。我们的实验揭示了在每个任务中使用Transformer所获得的各种训练技巧和显著性能优势，包括与RNN相比，在13/15个ASR基准测试中Transformer的惊人优越性。我们正在准备使用开源和公开可用的数据集，以Kaldi风格的可复制配方来发布所有ASR、ST和TTS任务的配方，以便社区能够继承我们令人兴奋的成果。

## Wenet

**WeNet Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit**

论文链接：https://arxiv.org/abs/2102.01547

在本文中，我们提出了一个名为WeNet的开源、面向生产并且生产就绪的语音识别工具包。在WeNet中，我们实现了一种新的两阶段方法，将流式和非流式端到端（E2E）语音识别统一到一个模型中。WeNet的主要动机是要缩小E2E语音识别模型的研究和生产之间的差距。WeNet提供了一种有效的方式来在多种实际场景中运行ASR应用程序，这是与其他开源E2E语音识别工具包的主要区别和优势。在我们的工具包中，我们实施了一种新的两阶段方法。我们的方法提出了一种基于动态块的注意力策略，允许在混合CTC/注意力架构中修改任意右上下文长度。推理延迟可以通过仅更改块大小来轻松控制。然后，通过注意力解码器对CTC假设进行重新评分以获得最终结果。我们在AISHELL-1数据集上使用WeNet进行的实验证明，与标准的非流式Transformer相比，我们的模型在非流式ASR中实现了5.03％的相对字符错误率（CER）降低。在模型量化之后，我们的模型表现出了合理的实时传输率（RTF）和延迟。



**Wenet2.0 More Productive End-to-End Speech Recognition Toolkit**

论文链接：https://arxiv.org/abs/2203.15455

最近，我们发布了WeNet，一个面向生产的端到端语音识别工具包，引入了一个统一的两阶段（U2）框架和一个内置的运行时，以在单个模型中处理流式和非流式解码模式。为了进一步提高ASR性能并满足各种生产需求，在本文中，我们提出了WeNet 2.0，其中包括四个重要的更新：

1. 我们提出了U2++，一个具有双向注意力解码器的统一两阶段框架，通过右到左的注意力解码器包括未来的上下文信息，以提高共享编码器的表征能力和在重评分阶段的性能。
2. 我们引入了基于n-gram的语言模型和基于WFST的解码器到WeNet 2.0，促进了在生产场景中使用丰富的文本数据。
3. 我们设计了一个统一的上下文偏置框架，利用用户特定的上下文信息（例如联系人列表），为生产提供快速适应能力，并提高了在有语言模型和无语言模型情况下的ASR准确性。
4. 我们设计了一个统一的输入/输出界面，支持大规模数据以有效训练模型。

总之，全新的WeNet 2.0在各种语料库上相对于原始WeNet实现了高达10％的识别性能提升，并提供了几个重要的面向生产的功能。

## 语音识别编码器

**Conformer-Convolution-augmented Transformer for Speech Recognition**

论文链接：https://arxiv.org/abs/2005.08100

最近，基于Transformer和卷积神经网络（CNN）的模型在自动语音识别（ASR）中表现出了有希望的结果，超越了循环神经网络（RNN）。Transformer模型擅长捕捉基于内容的全局交互，而CNN有效地利用局部特征。在这项工作中，我们通过研究如何以参数高效的方式结合卷积神经网络和Transformer来模拟音频序列的局部和全局依赖关系，实现了两者的最佳结合。为此，我们提出了用于语音识别的卷积增强Transformer，名为Conformer。Conformer在性能上显著优于以前的Transformer和CNN模型，实现了最先进的准确性。在广泛使用的LibriSpeech基准测试中，我们的模型在没有使用语言模型的情况下在test/testother上实现了WER为2.1％/4.3％，在使用外部语言模型的情况下为1.9％/3.9％。我们还观察到，仅有10M参数的小型模型也表现出了有竞争力的性能，为2.7％/6.3％。



**Paraformer-Fast and Accurate Parallel Transformer for Non-autoregressive**

论文链接：https://arxiv.org/abs/2206.08317

最近，Transformer模型在ASR领域取得了主导地位。尽管能够实现良好的性能，但它们涉及使用自回归（AR）解码器逐个生成标记，这在计算上效率低下。为了加速推理过程，设计了非自回归（NAR）方法，例如单步NAR，以实现并行生成。然而，由于在输出标记之间存在独立性假设，单步NAR的性能较差，特别是在大规模语料库中。提高单步NAR存在两个挑战：首先准确预测输出标记的数量并提取隐藏变量；其次增强输出标记之间的相互依赖建模。为了解决这两个挑战，我们提出了一种快速而准确的并行Transformer，称为Paraformer。这利用了基于连续积分-发射的预测器来预测标记的数量并生成隐藏变量。然后，一个浏览语言模型（GLM）采样器生成语义嵌入，以增强NAR解码器建模上下文相互依赖的能力。最后，我们设计了一种生成最小词错误率训练的负样本的策略，以进一步提高性能。使用公共的AISHELL-1、AISHELL-2基准测试以及一个工业级别的20,000小时任务的实验表明，所提出的Paraformer可以实现与最先进的AR Transformer相当的性能，并且速度提高了10倍以上。



**LFEformer-Local Feature Enhancement Using Sliding Window With Deformability for Automatic Speech Recognition**

论文链接：https://ieeexplore.ieee.org/document/10035529

本文提出了一种使用带变形性的滑动窗口模块，缩写为SWD，用于局部特征增强。具体而言，所提出的SWD模块采用基于嵌入网络层深度的可变大小的窗口。此外，所提出的SWD模块被插入到Transformer网络中，称为LFEformer，用于自动语音识别。这种网络特别擅长捕捉局部和全局特征，对于模型的改进是有益的。值得一提的是，局部特征和全局特征分别由SWD模块和Transformer网络中的注意机制提取。LFEformer的有效性已在三个广泛使用的数据集上进行了验证，这些数据集分别是Aishell-1、HKUST和WSJ（dev93/eval92）。实验结果表明，在相应的数据集中，可以获得0.5％ CER、0.8％ CER和0.7％/0.3％ WER的改进。



**Squeezeformer-An Efficient Transformer for Automatic Speech Recognition**

论文链接：https://arxiv.org/abs/2206.00888

最近提出的Conformer模型已成为基于其混合注意力-卷积架构的各种下游语音任务的事实标杆模型，该架构捕捉了局部和全局特征。然而，通过一系列系统研究，我们发现Conformer架构的设计选择并不是最佳的。在重新审视Conformer的宏观和微观架构的设计选择后，我们提出了Squeezeformer，在相同的训练方案下持续优于最先进的ASR模型。具体来说，对于宏观架构，Squeezeformer包括（i）Temporal U-Net结构，可以降低多头注意力模块在长序列上的计算成本，以及（ii）一个更简单的块结构，由多头注意力或卷积模块后跟前馈模块组成，而不是Conformer中提出的Macaron结构。此外，对于微观架构，Squeezeformer（i）简化了卷积块中的激活函数，（ii）删除了多余的层归一化操作，（iii）引入了一个高效的深度可分层降采样层，以高效地对输入信号进行下采样。Squeezeformer在没有外部语言模型的情况下，在LibriSpeech测试集上实现了7.5％、6.5％和6.0％的词错误率（WER）的最先进结果，比相同FLOP数量的Conformer-CTC好3.1％、1.4％和0.6％。我们的代码是开源的，可在线获取。

## 语音模型微调

**FINE-TUNING OF PRE-TRAINED END-TO-END SPEECH RECOGNITION WITH GENERATIVE ADVERSARIAL NETWORKS**

论文链接：https://arxiv.org/abs/2103.13329

最近，使用生成对抗网络（GAN）对低资源ASR语料库进行端到端（E2E）ASR系统的对抗训练已经开始探索。GAN有助于通过一个两个玩家的极小极大博弈来学习真实的数据表示。然而，使用GAN框架对大型ASR语料库进行E2E ASR模型的训练从未被探索过，因为由于高方差的梯度更新和收敛问题，这可能需要过长的时间。在本文中，我们引入了一种新的框架，用于使用GAN目标微调预训练的ASR模型，其中ASR模型充当生成器，而鉴别器试图区分ASR输出和真实数据。由于ASR模型是预先训练的，我们假设ASR模型的输出（软分布向量）有助于从鉴别器获得更高的分数，并在我们的GAN框架内使鉴别器的任务更加困难，从而提高了在微调阶段的ASR模型的性能。在这里，预训练的ASR模型通过额外的对抗损失对抗性地针对鉴别器进行微调。对全面的LibriSpeech数据集的实验显示，我们提出的方法优于基线和传统的基于GAN的对抗模型。



**Pre-train, Prompt, and Predict A Systematic Survey of Prompting Methods in Natural Language Processing**

论文连接：https://arxiv.org/abs/2107.13586

这篇论文对自然语言处理中的一种新范式进行了调查和整理，我们将其称为“基于提示的学习”。与传统的监督学习不同，传统监督学习训练一个模型，使其接收输入x并预测输出y，即P(y|x)。基于提示的学习是基于直接建模文本概率的语言模型。为了使用这些模型执行预测任务，原始输入x使用模板修改成具有一些未填充槽位的文本提示x0，然后使用语言模型以概率方式填充未填充信息，从而获得最终的字符串xˆ，可以从中推导出最终的输出y。这个框架有很多优点和吸引力：它允许语言模型在大量原始文本上进行预训练，通过定义新的提示函数，模型能够进行少样本甚至零样本学习，适应新的场景，只需很少或没有标记的数据。在本文中，我们介绍了这个有前途的范式的基本概念，描述了一组统一的数学符号，可以涵盖各种现有工作，还沿着几个维度组织了现有的工作，例如预训练模型的选择、提示和调整策略。为了使这个领域对感兴趣的初学者更加可访问，我们不仅对现有工作进行了系统回顾，并高度结构化地总结了基于提示的概念，还发布了其他资源，例如包括不断更新的调查和论文列表的NLPedia-Pretrain网站。



**ZERO-SHOT DOMAIN-SENSITIVE SPEECH RECOGNITION WITH PROMPT-CONDITIONING FINE-TUNING**

论文链接：https://arxiv.org/abs/2307.10274

在这项工作中，我们提出了一种方法，可以创建具有领域敏感性的语音识别模型，通过将其生成与给定的文本提示相结合，利用文本领域信息。这是通过对预训练的端到端模型（Whisper）进行微调，使其能够从具有提示示例的演示中学习而实现的。我们展示了这种能力可以泛化到不同领域甚至不同的提示上下文，我们的模型在不同领域的未见数据集上可以获得高达33%的词错误率（WER）降低，包括医疗对话、空中交通管制通信和金融会议等。考虑到音频文本-数据对的有限可用性，我们进一步将我们的方法扩展到仅文本微调，以实现领域敏感性和领域适应性。我们证明我们的仅文本微调模型也可以适应各种提示上下文，其中在医疗对话数据集上，该模型达到了29%的WER降低。



**DOMAIN PROMPTS: TOWARDS MEMORY AND COMPUTE EFFICIENT DOMAIN ADAPTATION OF ASR SYSTEMS**

论文链接：https://arxiv.org/abs/2112.08718v1

自动语音识别（ASR）系统已在各种各样的领域应用中找到了用途。由于领域特定的系统在领域内评估中表现优于其通用对应物，因此显然需要具备存储和计算高效的领域自适应。特别是，对于用于重新评分ASR假设的参数大的基于Transformer的语言模型进行适应具有挑战性。在这项工作中，我们介绍了领域提示（domain-prompts）方法，该方法训练了少量领域令牌嵌入参数，以使基于Transformer的语言模型适应特定领域。仅使用每个领域的少量额外参数，我们在未经调整的语言模型基线上实现了7-14%的词错误率（WER）改善。尽管参数高效，但这些改善效果与拥有数亿参数的完全微调模型相当。通过在提示大小、数据集大小、初始化和领域上进行消融实验，我们提供了使用领域提示在ASR系统中的好处的证据。



**Prompting Large Language Models for Zero-Shot Domain Adaptation in Speech Recognition**

论文链接：https://arxiv.org/abs/2306.16007

Language Models (LMs) 的整合已被证明是解决语音识别中领域偏移的有效方法。然而，这些方法通常需要大量的目标领域文本数据来训练LMs。与这些方法不同的是，在本工作中，我们仅使用特定领域的文本提示，提出了两种零样本ASR领域自适应方法，使用了一个70亿参数的大型语言模型（LLM）LLaMA。LLM的应用方式有两种：1）二次通行重排序：使用LLaMA对给定ASR系统的N个最佳假设进行重新排序；2）深度LLM融合：将LLM合并到基于编码器-解码器的ASR系统的解码器中。实验表明，仅使用一个领域提示，这两种方法都可以有效降低超出领域的TedLium-2和SPGISpeech数据集上的词错误率（WER）。特别是，深度LLM融合具有更好的实体识别和超出词汇词汇的召回率优势。



**Efficient Adapter Transfer of Self-Supervised Speech Models for Automatic Speech Recognition**

论文链接：https://arxiv.org/abs/2202.03218

自监督学习（SSL）是一种强大的工具，允许从未标记的数据中学习底层表示。基于Transformer的模型，如wav2vec 2.0和HuBERT，正在主导语音领域。通常，这些模型会在少量标记数据上进行微调，用于下游任务，如自动语音识别（ASR）。这涉及重新为每个任务训练大部分模型。适配器是小型轻量级模块，通常用于自然语言处理（NLP），以将预训练模型适应新任务。在本文中，我们提出将适配器应用于wav2vec 2.0，以减少下游ASR任务所需的参数数量，并增加模型对多个任务或语言的可扩展性。使用适配器，我们可以在每个任务训练少于10％的参数的情况下执行ASR，而与完全微调相比性能几乎没有降低。消融实验表明，仅将适配器应用于预训练网络的顶层可以获得与完全迁移相似的性能，支持高度预训练的层次编码更多的音素信息的理论，并进一步优化效率。



**Prompt Tuning GPT-2 language model for parameter-efficient domain adaptation of ASR systems**

论文链接：https://arxiv.org/abs/2112.08718

自动语音识别（ASR）系统已在各种不同领域的众多工业应用中找到了用武之地，因此需要适应具有小内存和部署开销的新领域。在本研究中，我们介绍了一种称为“领域提示”的方法，该方法涉及训练少量领域嵌入参数，以引导基于Transformer的语言模型（LM）进入特定领域。使用这个经过领域调整的LM对ASR假设进行重新评分，可以在仅有1000个未标记的领域特定文本句子的情况下，实现7-13%的词错误率（WER）降低。尽管仅更新了基本LM的0.02%的参数，但这一改进与完全微调的模型相当甚至更好。此外，我们的方法适合部署，因为学到的领域嵌入是前缀添加到模型的输入而不是更改基本模型架构。因此，我们的方法是ASR系统中LM的即时适应的理想选择，可以逐渐扩展到新领域。

